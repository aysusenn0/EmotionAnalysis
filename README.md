# ğŸ‡¹ğŸ‡· Derin Ã–ÄŸrenme ile TÃ¼rkÃ§e MaÄŸaza YorumlarÄ± Duygu Analizi Projesi

Bu proje, e-ticaret maÄŸaza yorumlarÄ±nÄ± kullanarak metinlerin duygusal tonunu (Olumlu/Olumsuz) **Ã‡ift YÃ¶nlÃ¼ Uzun-KÄ±sa SÃ¼reli Bellek (BiLSTM)** sinir aÄŸÄ± ile sÄ±nÄ±flandÄ±rmayÄ± amaÃ§lamaktadÄ±r. Proje, hem teknik uygulama hem de bilimsel raporlama kriterlerini karÅŸÄ±lamak Ã¼zere geliÅŸtirilmiÅŸtir.

---

## 1. Proje Konusu ve Ã–nemi 

### 1.1. Projenin SeÃ§ilme GerekÃ§esi ve Ä°lgili AlanÄ±n Ã–nemi
GÃ¼ncel e-ticaret platformlarÄ±nda, kullanÄ±cÄ± yorumlarÄ±nÄ±n hacmi geleneksel analiz yÃ¶ntemlerini aÅŸmÄ±ÅŸtÄ±r. Proje, bu bÃ¼yÃ¼k veri yÄ±ÄŸÄ±nÄ±nÄ± otomatik olarak sÄ±nÄ±flandÄ±rarak **MÃ¼ÅŸteri Geri Bildirimlerinin AnlÄ±k Analizi** iÃ§in kritik bir araÃ§ sunar.

### 1.2. Ä°lgili Alanda YapÄ±lan Uygulamalara KarÅŸÄ±laÅŸtÄ±rmalÄ± BakÄ±ÅŸ
Duygu analizi, Makine Ã–ÄŸrenmesi (ML) ve Derin Ã–ÄŸrenme (DL) tekniklerinin kesiÅŸim noktasÄ±ndadÄ±r.
* **Geleneksel ML (SVM, Naive Bayes):** HÄ±zlÄ±dÄ±r ancak kelimelerin sÄ±rasÄ±nÄ± ve dolayÄ±sÄ±yla **baÄŸlamÄ±** kaybeder.
* **Derin Ã–ÄŸrenme (DL):** Metin dizilerindeki karmaÅŸÄ±k ve uzun vadeli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenerek daha yÃ¼ksek doÄŸruluk saÄŸlar.

---

## 2. Veri Setinin Belirlenmesi ve Ã–n Ä°ÅŸleme 

### 2.1. Veri Seti
* **Kaynak:** Kaggle, "Duygu Analizi Ä°Ã§in ÃœrÃ¼n YorumlarÄ±"
* https://www.kaggle.com/datasets/burhanbilenn/duygu-analizi-icin-urun-yorumlari/data
* **Boyut:** Toplam 8484 adet yorum (eÄŸitim ve test iÃ§in ayrÄ±lmÄ±ÅŸtÄ±r).

### 2.2. Ã–n Ä°ÅŸleme ve Temizlik
1.  **SÄ±nÄ±flandÄ±rma:** Yorumlar, ikili sÄ±nÄ±flandÄ±rma (Olumlu/Olumsuz) iÃ§in etiketlenmiÅŸtir.
2.  **Metin TemizliÄŸi:** SayÄ±lar, noktalama iÅŸaretleri ve Ã¶zel karakterler kaldÄ±rÄ±lmÄ±ÅŸtÄ±r.
3.  **Kritik AdÄ±m:** Modelin anlamlÄ± kelimelere odaklanmasÄ± iÃ§in **TÃ¼rkÃ§e Stop Word (durma kelimesi) kaldÄ±rma** iÅŸlemi uygulanmÄ±ÅŸtÄ±r.
4.  **VektÃ¶rleÅŸtirme:** Yorumlar, modelin anlayabileceÄŸi sayÄ±sal dizilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ ve sÃ¶zlÃ¼k boyutu 4002 olarak belirlenmiÅŸtir.

---

## 3. Uygulanacak YÃ¶ntem/AlgoritmanÄ±n SeÃ§im GerekÃ§esi

### SeÃ§ilen YÃ¶ntem: Ã‡ift YÃ¶nlÃ¼ LSTM (BiLSTM)

BiLSTM, metin dizilerinde **baÄŸlamÄ± yakalama** konusunda Tek YÃ¶nlÃ¼ LSTM ve geleneksel ML'e gÃ¶re Ã¼stÃ¼nlÃ¼k saÄŸlar.

* **Tek YÃ¶nlÃ¼ LSTM vs. BiLSTM:** Tek YÃ¶nlÃ¼ LSTM, bir kelimeyi yalnÄ±zca kendinden **Ã¶nceki** kelimelere bakarak yorumlarken, BiLSTM hem **ileri** hem de **geri** yÃ¶nde (cÃ¼mle sonundan baÅŸÄ±na) bilgi akÄ±ÅŸÄ± saÄŸlar. 
* **AvantajÄ±:** "ÃœrÃ¼n hÄ±zlÄ±ydÄ± **fakat** kalitesi hayal kÄ±rÄ±klÄ±ÄŸÄ±ydÄ±." gibi cÃ¼mlelerdeki "fakat" gibi zÄ±tlÄ±k bildiren baÄŸlaÃ§larÄ±n Ã¶ncesi ve sonrasÄ± arasÄ±ndaki kritik bilgiyi, BiLSTM etkin bir ÅŸekilde Ã¶ÄŸrenir. Bu, duygu analizi iÃ§in en dengeli ve yÃ¼ksek performanslÄ± Ã§Ã¶zÃ¼mÃ¼ sunar.

---

## 4. Model EÄŸitimi & Model DeÄŸerlendirilmesi 

### 4.1. Model EÄŸitimi Ã–zeti
* **Model Mimarisi:** BiLSTM (Gizli Katman Boyutu: 128)
* **Optimizasyon:** Adam Optimizer
*  Ã–ÄŸrenme OranÄ±: 0.005
* **Epoch SayÄ±sÄ±:** 12
* **EÄŸitim Sonucu (Acc):** %95.04
*  **Ä°lk learning rate 0.001'e gÃ¶re Ã§ok daha iyi bir sonuÃ§ sergilediÄŸi iÃ§in nihai seÃ§imler seÃ§ildi.
* **Final EÄŸitim KaybÄ± (Loss)** | **0.135** |

### 4.2. DetaylÄ± Model DeÄŸerlendirmesi (Test Verisi Ãœzerinden)

Modelin gerÃ§ek dÃ¼nya performansÄ±nÄ± simÃ¼le eden test seti Ã¼zerindeki deÄŸerlendirmesi sonucunda, **%89.75** oranÄ±nda genel doÄŸruluk elde edilmiÅŸtir. SÄ±nÄ±f bazlÄ± metrikler aÅŸaÄŸÄ±da detaylandÄ±rÄ±lmÄ±ÅŸtÄ±r.

#### [1] DetaylÄ± SÄ±nÄ±flandÄ±rma Raporu (F1 Skoru)

| Metrik | Olumsuz (0) | Olumlu (1) | Weighted Avg (AÄŸÄ±rlÄ±klÄ± Ort.) |
| :--- | :--- | :--- | :--- |
| **Precision (Kesinlik)** | 0.8884 | 0.9064 | 0.8976 |
| **Recall (DuyarlÄ±lÄ±k)** | 0.9034 | 0.8918 | 0.8975 |
| **F1-Score** | **0.8958** | **0.8991** | **0.8975** |
| **DoÄŸruluk (Accuracy)** | - | - | **0.8975** |

#### [2] KarÄ±ÅŸÄ±klÄ±k Matrisi ve Hata Analizi

Modelin test setindeki 1697 yorum Ã¼zerindeki tahmin daÄŸÄ±lÄ±mÄ± ÅŸu ÅŸekildedir:

`Matris Ã‡Ä±ktÄ±sÄ±: [[748, 80], [94, 775]]`


> **SonuÃ§ Analizi:** Model, YanlÄ±ÅŸ Negatif (94) ve YanlÄ±ÅŸ Pozitif (80) hatalarÄ± arasÄ±nda oldukÃ§a **dengeli bir daÄŸÄ±lÄ±m** sergiledi.. Ä°ki hata tÃ¼rÃ¼ arasÄ±ndaki farkÄ±n az olmasÄ±, modelin belirli bir sÄ±nÄ±fa karÅŸÄ± (bias) Ã¶nyargÄ±lÄ± olmadÄ±ÄŸÄ±nÄ± ve genelleme yeteneÄŸinin yÃ¼ksek olduÄŸunu kanÄ±tlar.

## 5. Proje DokÃ¼mantasyonu ve Kod DÃ¼zeni 

Projenin yapÄ±sÄ±, sÃ¼rdÃ¼rÃ¼lebilirlik ve yeniden Ã¼retilebilirlik ilkelerine uygun olarak dÃ¼zenlenmiÅŸtir:

* `train.py`: Modelin eÄŸitimi, deÄŸerlendirilmesi ve modelin/sÃ¶zlÃ¼ÄŸÃ¼n kaydedilmesi.
* `model_utils.py`: Model mimarisi (`BiLSTM`) ve veri temizleme (`clean_text`) fonksiyonlarÄ±nÄ±n merkezi.
* `model_serve.py`: EÄŸitilmiÅŸ modelin Gradio ile web arayÃ¼zÃ¼nde sunulmasÄ±.
* `final_model_data.pth`: EÄŸitilmiÅŸ model aÄŸÄ±rlÄ±klarÄ±nÄ± ve kelime sÃ¶zlÃ¼ÄŸÃ¼nÃ¼ iÃ§erir.
* `README.md`: Bu dokÃ¼mantasyon, projenin tÃ¼m aÅŸamalarÄ±nÄ± ve sonuÃ§larÄ±nÄ± aÃ§Ä±klar.

---
# EN Sentiment Analysis of Turkish Store Reviews with Deep Learning

This project performs sentiment classification (Positive/Negative) on Turkish e-commerce product reviews using a **Bidirectional Long Short-Term Memory (BiLSTM)** deep learning model.

---

## 1. Project Topic and Importance

### 1.1. Motivation  
The rapid growth of customer reviews on online platforms exceeds the limits of manual analysis. Automated sentiment classification supports **real-time customer feedback monitoring**, which is crucial for decision-making in e-commerce systems.

### 1.2. Comparison with Existing Approaches  
- **Traditional ML (SVM, Naive Bayes):** Fast but fails to capture word order and context.  
- **Deep Learning:** Learns sequential dependencies and achieves higher accuracy.

---

## 2. Dataset and Preprocessing

### 2.1. Dataset  
- **Source:** Kaggle â€“ â€œDuygu Analizi Ä°Ã§in ÃœrÃ¼n YorumlarÄ±â€  
- **Link:** https://www.kaggle.com/datasets/burhanbilenn/duygu-analizi-icin-urun-yorumlari/data  
- **Size:** 8,484 Turkish product reviews  

### 2.2. Preprocessing  
- Binary label assignment (Positive / Negative)  
- Removal of numbers, punctuation, and special characters  
- Turkish stop-word removal  
- Text vectorization into integer sequences  
- **Vocabulary size:** 4,002  

---

## 3. Methodology

### 3.1. Selected Method: Bidirectional LSTM (BiLSTM)  
BiLSTM processes sequences in both forward and backward directions, allowing better understanding of contextual transitions.

Example:  
*â€œÃœrÃ¼n hÄ±zlÄ±ydÄ± fakat kalitesi hayal kÄ±rÄ±klÄ±ÄŸÄ±ydÄ±.â€*  
The contrast introduced by *â€œfakatâ€* is captured more effectively by BiLSTM.

---

## 4. Model Training and Evaluation

### 4.1. Training Summary  
- **Model:** BiLSTM  
- **Hidden Size:** 128  
- **Optimizer:** Adam  
- **Learning Rate:** 0.005  
- **Epochs:** 12  
- **Training Accuracy:** 95.04%  
- **Final Loss:** 0.135  

### 4.2. Test Results  

#### Classification Report

| Metric | Negative (0) | Positive (1) | Weighted Avg |
|--------|--------------|--------------|--------------|
| Precision | 0.8884 | 0.9064 | 0.8976 |
| Recall | 0.9034 | 0.8918 | 0.8975 |
| F1-Score | 0.8958 | 0.8991 | 0.8975 |
| Accuracy | â€“ | â€“ | **0.8975** |

#### Confusion Matrix  : 
[[748, 80], [94, 775]]

**Interpretation:**  
False Positives (80) and False Negatives (94) are balanced, indicating that the model is not biased toward any class.

