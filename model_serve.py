import torch
import gradio as gr
import os

# Ortak dosyadan modeli ve temizlik fonksiyonunu Ã§ekiyoruz
from model_utils import BiLSTM, clean_text


# MODELÄ° VE SÃ–ZLÃœÄÃœ YÃœKLEME

model_path = "final_model_data.pth"

if not os.path.exists(model_path):
    print("HATA: Model dosyasÄ± bulunamadÄ±! LÃ¼tfen Ã¶nce 'train.py' dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n.")
    exit()

print("Model yÃ¼kleniyor...")
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# KaydettiÄŸimiz paketi yÃ¼klÃ¼yoruz
checkpoint = torch.load(model_path, map_location=device)

# SÃ¶zlÃ¼ÄŸÃ¼ ve parametreleri alÄ±yoruz
vocab = checkpoint['vocab']
vocab_size = checkpoint['vocab_size']

model = BiLSTM(vocab_size)
model.load_state_dict(checkpoint['model_state_dict'])
model.to(device)
model.eval()  # DeÄŸerlendirme modu

print("âœ… Model ve SÃ¶zlÃ¼k baÅŸarÄ±yla yÃ¼klendi.")



def text_pipeline(text):
    # Metni temizle
    text = clean_text(text)
    tokens = text.split()
    # YÃ¼klenen sÃ¶zlÃ¼ÄŸÃ¼ kullanarak sayÄ±ya Ã§evir
    token_ids = [vocab.get(token, 1) for token in tokens]  # 1: <unk>

    MAX_LEN = 60
    if len(token_ids) < MAX_LEN:
        token_ids += [0] * (MAX_LEN - len(token_ids))  # 0: <pad>
    else:
        token_ids = token_ids[:MAX_LEN]

    return torch.tensor(token_ids, dtype=torch.long)


def tahmin_et(kullanici_yorumu):
    if not kullanici_yorumu: return "LÃ¼tfen bir yorum girin."

    # Veriyi hazÄ±rla
    vektor = text_pipeline(kullanici_yorumu).unsqueeze(0).to(device)

    # Tahmin
    with torch.no_grad():
        tahmin_skoru = model(vektor).item()
        olasilik = torch.sigmoid(torch.tensor(tahmin_skoru)).item()

    # SonuÃ§
    if olasilik > 0.50:  # EÅŸik deÄŸer
        sonuc = "OLUMLU ğŸ˜Š"
        renk = "green"
        guven = olasilik
    else:
        sonuc = "OLUMSUZ ğŸ˜"
        renk = "red"
        guven = 1 - olasilik

    return f"Tahmin: {sonuc}\nGÃ¼ven OranÄ±: %{guven * 100:.2f}"



# GRADIO ARAYÃœZÃœ

print("ArayÃ¼z baÅŸlatÄ±lÄ±yor...")

interface = gr.Interface(
    fn=tahmin_et,
    inputs=gr.Textbox(lines=2, placeholder="Yorumunuzu buraya yazÄ±n...", label="MÃ¼ÅŸteri Yorumu"),
    outputs=gr.Textbox(label="Yapay Zeka Analizi"),
    title="ğŸ›’ ÃœrÃ¼n YorumlarÄ± Duygu Analizi",
    description="LSTM Modeli kullanÄ±larak yorumun Olumlu mu yoksa Olumsuz mu olduÄŸunu tahmin eder.",
    examples=[
        ["ÃœrÃ¼n harika, Ã§ok beÄŸendim, kargo hÄ±zlÄ±ydÄ±."],
        ["Rezalet bir Ã¼rÃ¼n, sakÄ±n almayÄ±n, hemen bozuldu."],
        ["FiyatÄ±na gÃ¶re idare eder."],
        ["Paketleme Ã§ok kÃ¶tÃ¼ydÃ¼ ama Ã¼rÃ¼n Ã§alÄ±ÅŸÄ±yor."]
    ]

)
if __name__ == "__main__":
    interface.launch(share=True)